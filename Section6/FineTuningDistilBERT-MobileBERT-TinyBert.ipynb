{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import wandb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AutoConfig, TrainingArguments, Trainer, pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fine Tuning DistilBERT, MobileBERT and TinyBERT\n",
    "## for fake news detection"
   ],
   "id": "f0ee244104c951ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "warnings.filterwarnings(\"ignore\") #Don't do in production",
   "id": "19c3d36fe108a058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "eb1cd028b6fca178",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "8b1714c324a7fc00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#load_dotenv()",
   "id": "9a4f4537816c5790",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PROJECT_NAME = \"FakeNewsClassification\"\n",
    "RUN_NAME =  f\"{datetime.now():%Y-%m-%d_%H.%M.%S}\"\n",
    "HF_USER = \"CharlesMac\"\n",
    "PROJECT_RUN_NAME = f\"{PROJECT_NAME}-{RUN_NAME}\"\n",
    "HUB_MODEL_NAME = f\"{HF_USER}/{PROJECT_RUN_NAME}\"\n",
    "\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "LOG_INTO_WANDB = True\n",
    "BATCH_SIZE = 32\n",
    "TRAINING_DIR = \"train_dir\""
   ],
   "id": "b7e7db661e256c31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_excel('Data/fake_news.xlsx')\n",
    "df.head()"
   ],
   "id": "bf3b498a68f2a1ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "7f946cc0b147a1e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.dropna(inplace=True)",
   "id": "973f49c78c684eaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "1188281b8cfb4de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['label'].value_counts()",
   "id": "9cf150697d693a39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Analysis",
   "id": "6ad944a7e48aa331"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label_count = df['label'].value_counts(ascending=True)\n",
    "label_count.plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ],
   "id": "66030fbbeb932d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "1# 1.5 tokens per word on average\n",
    "df['title_tokens'] = df['title'].apply(lambda x: len(x.split())*1.5)\n",
    "df['text_tokens'] = df['text'].apply(lambda x: len(x.split())*1.5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].hist(df['title_tokens'], bins=50, color='b')\n",
    "ax[0].set_title(\"Title Tokens\")\n",
    "ax[1].hist(df['text_tokens'], bins=50, color='b')\n",
    "ax[1].set_title(\"Text Tokens\")\n",
    "plt.show()"
   ],
   "id": "ae3940797b6b4c48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataloader and Train Test Split",
   "id": "987a14acd10e072"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train, test = train_test_split(df, test_size=0.3,\n",
    "                                   random_state=42,\n",
    "                                   shuffle=True,\n",
    "                                   stratify=df['label'])\n",
    "\n",
    "test, validation = train_test_split(test, test_size=1/3,\n",
    "                                    random_state=42,\n",
    "                                    shuffle=True,\n",
    "                                    stratify=test['label'])"
   ],
   "id": "76cc76ddd4434842",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.shape, test.shape, validation.shape",
   "id": "4a6e47fcaf8419c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(train, preserve_index=False),\n",
    "        \"test\": Dataset.from_pandas(test, preserve_index=False),\n",
    "        \"validation\": Dataset.from_pandas(validation, preserve_index=False)\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset"
   ],
   "id": "b61ca5707fd8f8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Tokenization",
   "id": "5982bdfb6819b41f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "text = \"Machine learning is awesome\"",
   "id": "508a5e5a2fd070a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "distilbert_tokens = distilbert_tokenizer.tokenize(text)\n",
    "\n",
    "mobile_model_ckpt = \"google/mobilebert-uncased\"\n",
    "mobilebert_tokenizer = AutoTokenizer.from_pretrained(mobile_model_ckpt)\n",
    "mobilebert_tokens = mobilebert_tokenizer.tokenize(text)\n",
    "\n",
    "tiny_model_ckpt = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tinybert_tokenizer = AutoTokenizer.from_pretrained(tiny_model_ckpt)\n",
    "tinybert_tokens = tinybert_tokenizer.tokenize(text)"
   ],
   "id": "c37c47dbe96b99e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "distilbert_tokenizer, mobilebert_tokenizer, tinybert_tokenizer",
   "id": "23f8a63f8e610d17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokenize(batch):\n",
    "    tokens = distilbert_tokenizer(batch['title'], padding=True, truncation=True)\n",
    "    return tokens\n",
    "\n",
    "print (tokenize(dataset['train'][:2]))"
   ],
   "id": "f01a5c25b1e93ad7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "encoded_dataset = dataset.map(tokenize, batch_size=None, batched=True)",
   "id": "bbabc5bb345708dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Building",
   "id": "697b04f56c4ae079"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label2id = {\"Real\": 0, \"Fake\": 1}\n",
    "id2label = {0: \"Real\", 1: \"Fake\"}\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "num_labels = len(label2id)\n",
    "config = AutoConfig.from_pretrained(model_ckpt, label2id=label2id, id2label=id2label)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, config=config).to(device)"
   ],
   "id": "a5279714ad199c00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.config.id2label",
   "id": "c925aa567d8e6eea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b4599d8b90cc0866",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine Tuning",
   "id": "c277cf13f4cc4557"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Log in to HuggingFace\n",
    "\n",
    "# hf_token = os.environ['HF_TOKEN']\n",
    "# login(hf_token, add_to_git_credential=True)"
   ],
   "id": "d0319cce02c67397",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# wandb_api_key = os.environ['WANDB_API_KEY']\n",
    "# os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n",
    "# wandb.login()\n",
    "# #\n",
    "# # # Configure Weights & Biases to record against our project\n",
    "# os.environ[\"WANDB_PROJECT\"] = PROJECT_NAME\n",
    "# os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\" if LOG_INTO_WANDB else \"end\"\n",
    "# os.environ[\"WANDB_WATCH\"] = \"gradients\""
   ],
   "id": "6927be4883965733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# if LOG_INTO_WANDB:\n",
    "#     wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ],
   "id": "df93b93e99d079b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "accuracy = evaluate.load(\"accuracy\")",
   "id": "bdb3c22d27241ddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_metrics_evaluate(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ],
   "id": "735899d76da739d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ],
   "id": "4d03813d8cadb3b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(output_dir=TRAINING_DIR,\n",
    "                                  overwrite_output_dir=True,\n",
    "                                  num_train_epochs=EPOCHS,\n",
    "                                  learning_rate=LEARNING_RATE,\n",
    "                                  per_device_train_batch_size=BATCH_SIZE,\n",
    "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
    "                                  report_to=None,\n",
    "#                                  report_to=\"wandb\" if LOG_INTO_WANDB else None,\n",
    "                                  run_name=RUN_NAME,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  disable_tqdm=False,\n",
    "                                  # hub_model_id=HUB_MODEL_NAME,\n",
    "                                  # hub_private_repo=True\n",
    "                                  )"
   ],
   "id": "6e2747463ca96298",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  compute_metrics=compute_metrics_evaluate,\n",
    "                  train_dataset=encoded_dataset['train'],\n",
    "                  eval_dataset=encoded_dataset['validation'],\n",
    "                  tokenizer=distilbert_tokenizer)"
   ],
   "id": "c40575a534fca395",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "d99d699ea5f0fac4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.save_model(\"Models/fake_news\" + RUN_NAME)",
   "id": "ab0891d8e18db4c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Evaluation",
   "id": "2fae3eafa60da273"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "preds_output = trainer.predict(encoded_dataset['test'])",
   "id": "ffcbce916ec39ed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "preds_output.metrics",
   "id": "1a8c6188556244f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
    "y_true = encoded_dataset['test'][:]['label']"
   ],
   "id": "23ebd0c6ce029294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(classification_report(y_true, y_pred, target_names=list(label2id)))",
   "id": "5e62180da1b1dc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(cm, annot=True, xticklabels=label2id.keys(), yticklabels=label2id.keys(), fmt='d', cbar=False, cmap='Reds')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ],
   "id": "bf668b7d0a68cd60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model benchmarking",
   "id": "9876b78350fe71ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_dict = {\n",
    "    \"bert-base\":\"bert-base-uncased\",\n",
    "    \"distilbert\":\"distilbert-base-uncased\",\n",
    "    \"mobilebert\":\"google/mobilebert-uncased\",\n",
    "    \"tinybert\":\"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "}"
   ],
   "id": "c56c4dec11cabbfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_model(model_name):\n",
    "    model_ckpt = model_dict[model_name]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    config = AutoConfig.from_pretrained(model_ckpt, label2id=label2id, id2label=id2label)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n",
    "\n",
    "    def local_tokenizer(batch):\n",
    "        tokens = tokenizer.tokenize(batch['title'], padding=True, truncation=True)\n",
    "        return tokens\n",
    "\n",
    "    trainer = Trainer(model=model,\n",
    "                      args=training_args,\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      train_dataset=encoded_dataset['train'],\n",
    "                      eval_dataset=encoded_dataset['validation'],\n",
    "                      tokenizer=tokenizer)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    preds = trainer.predict(encoded_dataset['test'])\n",
    "    trainer.save_model(\"Models/fake_news\" + model_ckpt + RUN_NAME)\n",
    "    return preds.metrics\n"
   ],
   "id": "3e6d5cd9bdaae685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_performance = {}\n",
    "for model_name in model_dict:\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Training Model: \", model_name)\n",
    "    start = time.time()\n",
    "    result = train_model(model_name)\n",
    "    end = time.time()\n",
    "    model_performance[model_name] = {model_name: result, \"time taken\": end-start}"
   ],
   "id": "86f6251219334ebf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_performance",
   "id": "17754d665d8d7628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "{'bert-base': {'test_loss': 0.14568275213241577,\n",
    "  'test_accuracy': 0.9606126914660832,\n",
    "  'test_f1': 0.960656369998893,\n",
    "  'test_runtime': 2.4963,\n",
    "  'test_samples_per_second': 1464.584,\n",
    "  'test_steps_per_second': 46.069},\n",
    " 'distilbert': {'test_loss': 0.1263875514268875,\n",
    "  'test_accuracy': 0.962527352297593,\n",
    "  'test_f1': 0.9625578288439263,\n",
    "  'test_runtime': 1.3223,\n",
    "  'test_samples_per_second': 2764.84,\n",
    "  'test_steps_per_second': 86.968},\n",
    " 'mobilebert': {'test_loss': 0.13580088317394257,\n",
    "  'test_accuracy': 0.9488512035010941,\n",
    "  'test_f1': 0.9489814357607576,\n",
    "  'test_runtime': 1.4697,\n",
    "  'test_samples_per_second': 2487.511,\n",
    "  'test_steps_per_second': 78.245},\n",
    " 'tinybert': {'test_loss': 0.1453436017036438,\n",
    "  'test_accuracy': 0.9447483588621444,\n",
    "  'test_f1': 0.9446144684798617,\n",
    "  'test_runtime': 0.4243,\n",
    "  'test_samples_per_second': 8616.846,\n",
    "  'test_steps_per_second': 271.044}}"
   ],
   "id": "5377adac3522bd6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# if LOG_INTO_WANDB:\n",
    "#     wandb.finish()"
   ],
   "id": "c594f2473784afd0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchTrain",
   "language": "python",
   "name": "pytorchtrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
